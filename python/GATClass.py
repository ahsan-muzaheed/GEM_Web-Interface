import torch.nn as nn
from torch.optim import Adam
import torch
from GATLayerClass import GATLayer


class GAT(torch.nn.Module):
    """
    The most interesting and hardest implementation is implementation #3.
    Imp1 and imp2 differ in subtle details but are basically the same thing.

    So I'll focus on imp #3 in this notebook.

    """

    def __init__(
        self,
        num_of_layers,
        num_heads_per_layer,
        num_features_per_layer,
        add_skip_connection=True,
        bias=True,
        dropout=0.6,
        log_attention_weights=False,
    ):
        super().__init__()
        assert (
            num_of_layers == len(num_heads_per_layer) == len(num_features_per_layer) - 1
        ), f"Enter valid arch params."

        num_heads_per_layer = [
            1
        ] + num_heads_per_layer  # trick - so that I can nicely create GAT layers below

        gat_layers = []  # collect GAT layers
        for i in range(num_of_layers):
            layer = GATLayer(
                num_in_features=num_features_per_layer[i]
                * num_heads_per_layer[i],  # consequence of concatenation
                num_out_features=num_features_per_layer[i + 1],
                num_of_heads=num_heads_per_layer[i + 1],
                concat=True
                if i < num_of_layers - 1
                else False,  # last GAT layer does mean avg, the others do concat
                activation=nn.ELU()
                if i < num_of_layers - 1
                else None,  # last layer just outputs raw scores
                dropout_prob=dropout,
                add_skip_connection=add_skip_connection,
                bias=bias,
                log_attention_weights=log_attention_weights,
            )
            gat_layers.append(layer)

        self.gat_net = nn.Sequential(
            *gat_layers,
        )

    # data is just a (in_nodes_features, edge_index) tuple, I had to do it like this because of the nn.Sequential:
    # https://discuss.pytorch.org/t/forward-takes-2-positional-arguments-but-3-were-given-for-nn-sqeuential-with-linear-layers/65698
    def forward(self, data):
        return self.gat_net(data)
